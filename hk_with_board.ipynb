{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\USER\\Anaconda3\\lib\\site-packages\\h5py\\__init__.py:34: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_x:(226, 5)\n",
      "train_y:(226, 1)\n",
      "train_y content:[[1]\n",
      " [1]\n",
      " [1]]\n",
      "valid_x:(57, 5)\n",
      "valid_y:(57, 1)\n"
     ]
    }
   ],
   "source": [
    "train_data = pd.read_csv(\"data/hk_training.csv\")\n",
    "test_data = pd.read_csv(\"data/hk_testing.csv\")\n",
    "\n",
    "def split_valid_test_data(data, fraction=(1 - 0.8)):\n",
    "    data_y = data[\"Output\"]\n",
    "    lb = LabelBinarizer()\n",
    "    data_y = lb.fit_transform(data_y)\n",
    "\n",
    "    data_x = data.drop([\"Output\"], axis=1)\n",
    "\n",
    "    train_x, valid_x, train_y, valid_y = train_test_split(data_x, data_y, test_size=fraction)\n",
    "\n",
    "    return train_x.values, train_y, valid_x, valid_y\n",
    "\n",
    "\n",
    "train_x, train_y, valid_x, valid_y = split_valid_test_data(train_data)\n",
    "print(\"train_x:{}\".format(train_x.shape))\n",
    "print(\"train_y:{}\".format(train_y.shape))\n",
    "print(\"train_y content:{}\".format(train_y[:3]))\n",
    "\n",
    "print(\"valid_x:{}\".format(valid_x.shape))\n",
    "print(\"valid_y:{}\".format(valid_y.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Build Neural Network\n",
    "from collections import namedtuple\n",
    "\n",
    "def build_neural_network(hidden_units=10):\n",
    "    tf.reset_default_graph()\n",
    "    inputs = tf.placeholder(tf.float32, shape=[None, train_x.shape[1]], name='Inputs')\n",
    "    labels = tf.placeholder(tf.float32, shape=[None, 1], name='Target')\n",
    "    learning_rate = tf.placeholder(tf.float32)\n",
    "    is_training=tf.Variable(True,dtype=tf.bool)\n",
    "    \n",
    "    initializer = tf.contrib.layers.xavier_initializer()\n",
    "    fc = tf.layers.dense(inputs, hidden_units, activation=None, kernel_initializer=initializer, name='fc')\n",
    "    fc = tf.layers.batch_normalization(fc, training=is_training)\n",
    "    fc = tf.nn.relu(fc)\n",
    "    tf.summary.histogram(\"fc\", fc)\n",
    "    \n",
    "    logits = tf.layers.dense(fc, 1, activation=None)\n",
    "    cross_entropy = tf.nn.sigmoid_cross_entropy_with_logits(labels=labels, logits=logits)\n",
    "    cost = tf.reduce_mean(cross_entropy)\n",
    "    tf.summary.histogram(\"cost\", cost)\n",
    "    \n",
    "    with tf.control_dependencies(tf.get_collection(tf.GraphKeys.UPDATE_OPS)):\n",
    "        optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate).minimize(cost)\n",
    "\n",
    "    predicted = tf.nn.sigmoid(logits)\n",
    "    correct_pred = tf.equal(tf.round(predicted), labels)\n",
    "    accuracy = tf.reduce_mean(tf.cast(correct_pred, tf.float32))\n",
    "\n",
    "    # Export the nodes \n",
    "    export_nodes = ['inputs', 'labels', 'learning_rate','is_training', 'logits',\n",
    "                    'cost', 'optimizer', 'predicted', 'accuracy']\n",
    "    Graph = namedtuple('Graph', export_nodes)\n",
    "    local_dict = locals()\n",
    "    graph = Graph(*[local_dict[each] for each in export_nodes])\n",
    "\n",
    "    return graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = build_neural_network()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_batch(data_x,data_y,batch_size=32):\n",
    "    batch_n=len(data_x)//batch_size\n",
    "    for i in range(batch_n):\n",
    "        batch_x=data_x[i*batch_size:(i+1)*batch_size]\n",
    "        batch_y=data_y[i*batch_size:(i+1)*batch_size]\n",
    "        \n",
    "        yield batch_x,batch_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "epochs = 200\n",
    "train_collect = 50\n",
    "train_print=train_collect*2\n",
    "\n",
    "learning_rate_value = 0.001\n",
    "batch_size=16\n",
    "\n",
    "x_collect = []\n",
    "train_loss_collect = []\n",
    "train_acc_collect = []\n",
    "valid_loss_collect = []\n",
    "valid_acc_collect = []\n",
    "\n",
    "saver = tf.train.Saver()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 8/200 Train Loss: 0.5087\n",
      "Epoch: 8/200 Validation Loss: 0.6095 Validation Acc: 0.6667\n",
      "Epoch: 15/200 Train Loss: 0.3508\n",
      "Epoch: 15/200 Validation Loss: 0.4344 Validation Acc: 0.9123\n",
      "Epoch: 22/200 Train Loss: 0.2633\n",
      "Epoch: 22/200 Validation Loss: 0.3583 Validation Acc: 0.8246\n",
      "Epoch: 29/200 Train Loss: 0.2069\n",
      "Epoch: 29/200 Validation Loss: 0.3150 Validation Acc: 0.8246\n",
      "Epoch: 36/200 Train Loss: 0.1647\n",
      "Epoch: 36/200 Validation Loss: 0.3891 Validation Acc: 0.8246\n",
      "Epoch: 43/200 Train Loss: 0.1305\n",
      "Epoch: 43/200 Validation Loss: 0.2551 Validation Acc: 0.8772\n",
      "Epoch: 50/200 Train Loss: 0.1118\n",
      "Epoch: 50/200 Validation Loss: 0.2117 Validation Acc: 0.9123\n",
      "Epoch: 58/200 Train Loss: 0.0971\n",
      "Epoch: 58/200 Validation Loss: 0.1733 Validation Acc: 0.9298\n",
      "Epoch: 65/200 Train Loss: 0.0866\n",
      "Epoch: 65/200 Validation Loss: 0.1563 Validation Acc: 0.9298\n",
      "Epoch: 72/200 Train Loss: 0.0815\n",
      "Epoch: 72/200 Validation Loss: 0.2031 Validation Acc: 0.8947\n",
      "Epoch: 79/200 Train Loss: 0.0742\n",
      "Epoch: 79/200 Validation Loss: 0.1552 Validation Acc: 0.9298\n",
      "Epoch: 86/200 Train Loss: 0.0705\n",
      "Epoch: 86/200 Validation Loss: 0.1755 Validation Acc: 0.9123\n",
      "Epoch: 93/200 Train Loss: 0.0604\n",
      "Epoch: 93/200 Validation Loss: 0.1375 Validation Acc: 0.9123\n",
      "Epoch: 100/200 Train Loss: 0.0555\n",
      "Epoch: 100/200 Validation Loss: 0.1212 Validation Acc: 0.9123\n",
      "Epoch: 108/200 Train Loss: 0.0519\n",
      "Epoch: 108/200 Validation Loss: 0.1128 Validation Acc: 0.9298\n",
      "Epoch: 115/200 Train Loss: 0.0490\n",
      "Epoch: 115/200 Validation Loss: 0.1081 Validation Acc: 0.9298\n",
      "Epoch: 122/200 Train Loss: 0.0463\n",
      "Epoch: 122/200 Validation Loss: 0.1068 Validation Acc: 0.9298\n",
      "Epoch: 129/200 Train Loss: 0.0443\n",
      "Epoch: 129/200 Validation Loss: 0.1704 Validation Acc: 0.8772\n",
      "Epoch: 136/200 Train Loss: 0.0374\n",
      "Epoch: 136/200 Validation Loss: 0.1863 Validation Acc: 0.8947\n",
      "Epoch: 143/200 Train Loss: 0.0332\n",
      "Epoch: 143/200 Validation Loss: 0.2604 Validation Acc: 0.8246\n",
      "Epoch: 150/200 Train Loss: 0.0310\n",
      "Epoch: 150/200 Validation Loss: 0.2146 Validation Acc: 0.8772\n",
      "Epoch: 158/200 Train Loss: 0.0288\n",
      "Epoch: 158/200 Validation Loss: 0.1668 Validation Acc: 0.9123\n",
      "Epoch: 165/200 Train Loss: 0.0267\n",
      "Epoch: 165/200 Validation Loss: 0.1288 Validation Acc: 0.9649\n",
      "Epoch: 172/200 Train Loss: 0.0245\n",
      "Epoch: 172/200 Validation Loss: 0.0607 Validation Acc: 0.9825\n",
      "Epoch: 179/200 Train Loss: 0.0222\n",
      "Epoch: 179/200 Validation Loss: 0.0541 Validation Acc: 1.0000\n",
      "Epoch: 186/200 Train Loss: 0.0209\n",
      "Epoch: 186/200 Validation Loss: 0.0512 Validation Acc: 1.0000\n",
      "Epoch: 193/200 Train Loss: 0.0192\n",
      "Epoch: 193/200 Validation Loss: 0.0586 Validation Acc: 0.9825\n",
      "Epoch: 200/200 Train Loss: 0.0180\n",
      "Epoch: 200/200 Validation Loss: 0.0450 Validation Acc: 1.0000\n"
     ]
    }
   ],
   "source": [
    "import datetime\n",
    "with tf.Session() as sess:\n",
    "    summaryMerged = tf.summary.merge_all()\n",
    "    t = str(datetime.datetime.now())\n",
    "    now = t[0:4] + t[5:7] + t[8:10] + t[11:13] + t[14:16] + t[17:19]\n",
    "    filename=\"./hk2_summary_log/run\" + now\n",
    "    writer = tf.summary.FileWriter(filename, sess.graph)\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    iteration=0\n",
    "    for e in range(epochs):\n",
    "        for batch_x,batch_y in get_batch(train_x,train_y,batch_size):\n",
    "            iteration+=1\n",
    "            feed = {model.inputs: train_x,\n",
    "                    model.labels: train_y,\n",
    "                    model.learning_rate: learning_rate_value,\n",
    "                    model.is_training:True\n",
    "                   }\n",
    "\n",
    "            train_loss, _, train_acc = sess.run([model.cost, model.optimizer, summaryMerged], feed_dict=feed)\n",
    "            writer.add_summary(train_acc, e)\n",
    "            \n",
    "            if iteration % train_collect == 0:\n",
    "                x_collect.append(e)\n",
    "                train_loss_collect.append(train_loss)\n",
    "                train_acc_collect.append(train_acc)\n",
    "\n",
    "                if iteration % train_print==0:\n",
    "                     print(\"Epoch: {}/{}\".format(e + 1, epochs), \"Train Loss: {:.4f}\".format(train_loss))\n",
    "                     # print(\"Epoch: {}/{}\".format(e + 1, epochs), \"Train Loss: {:.4f}\".format(train_loss), \"Train Acc: {}\".format(train_acc))\n",
    "                        \n",
    "                feed = {model.inputs: valid_x,\n",
    "                        model.labels: valid_y,\n",
    "                        model.is_training:False\n",
    "                       }\n",
    "                val_loss, val_acc = sess.run([model.cost, model.accuracy], feed_dict=feed)\n",
    "                valid_loss_collect.append(val_loss)\n",
    "                valid_acc_collect.append(val_acc)\n",
    "                \n",
    "                if iteration % train_print==0:\n",
    "                    print(\"Epoch: {}/{}\".format(e + 1, epochs),\n",
    "                      \"Validation Loss: {:.4f}\".format(val_loss),\n",
    "                      \"Validation Acc: {:.4f}\".format(val_acc))\n",
    "                \n",
    "\n",
    "    saver.save(sess, \"./hk2.ckpt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from ./hk2.ckpt\n",
      "[[6.19655367e-08]\n",
      " [8.30938079e-05]\n",
      " [9.93458450e-01]\n",
      " [9.99985218e-01]\n",
      " [9.99999404e-01]\n",
      " [9.99984145e-01]\n",
      " [9.99998689e-01]\n",
      " [1.31820026e-03]\n",
      " [5.21193603e-15]\n",
      " [8.48385505e-04]\n",
      " [2.09820405e-06]\n",
      " [9.44189250e-01]\n",
      " [5.37413778e-03]\n",
      " [9.99997616e-01]\n",
      " [9.99421120e-01]\n",
      " [9.99938607e-01]\n",
      " [9.57127035e-01]\n",
      " [1.14868941e-04]\n",
      " [9.99998808e-01]\n",
      " [9.99993205e-01]\n",
      " [9.99953747e-01]\n",
      " [9.99987841e-01]\n",
      " [9.99970794e-01]\n",
      " [9.99987125e-01]\n",
      " [9.99993443e-01]\n",
      " [9.99981046e-01]\n",
      " [9.99922633e-01]\n",
      " [9.99857068e-01]\n",
      " [9.99995470e-01]\n",
      " [9.99954581e-01]\n",
      " [1.54011250e-05]\n",
      " [9.91744936e-01]\n",
      " [9.99998450e-01]\n",
      " [9.99999046e-01]\n",
      " [9.99985456e-01]\n",
      " [9.99998331e-01]\n",
      " [9.99998450e-01]\n",
      " [9.96950746e-01]\n",
      " [9.99979615e-01]\n",
      " [9.99980807e-01]\n",
      " [9.99996781e-01]\n",
      " [9.99995351e-01]\n",
      " [9.99992490e-01]\n",
      " [9.99984384e-01]\n",
      " [9.99982595e-01]\n",
      " [9.99997854e-01]\n",
      " [9.99973416e-01]\n",
      " [9.99998689e-01]\n",
      " [9.99979854e-01]\n",
      " [9.99997139e-01]\n",
      " [9.99983072e-01]\n",
      " [9.99999046e-01]\n",
      " [9.99984622e-01]\n",
      " [9.96725559e-01]\n",
      " [9.99728143e-01]\n",
      " [9.99847412e-01]\n",
      " [8.92233670e-01]\n",
      " [9.99937177e-01]\n",
      " [9.99906421e-01]\n",
      " [9.99358594e-01]\n",
      " [7.75328577e-01]\n",
      " [1.89376359e-09]\n",
      " [9.99498487e-01]\n",
      " [9.99990225e-01]\n",
      " [9.99729097e-01]\n",
      " [9.11618114e-01]\n",
      " [9.99992728e-01]\n",
      " [9.99997377e-01]\n",
      " [9.99997735e-01]\n",
      " [9.99717534e-01]\n",
      " [9.99978185e-01]\n",
      " [3.67302378e-03]\n",
      " [9.99999523e-01]\n",
      " [9.99935865e-01]\n",
      " [9.99999285e-01]\n",
      " [9.99999642e-01]\n",
      " [9.19344366e-01]\n",
      " [9.99998212e-01]\n",
      " [9.76513207e-01]\n",
      " [9.99952197e-01]\n",
      " [2.45757510e-05]\n",
      " [9.99956012e-01]\n",
      " [9.99966502e-01]\n",
      " [9.99929190e-01]\n",
      " [9.99995351e-01]\n",
      " [3.55137163e-04]\n",
      " [4.96259145e-03]\n",
      " [9.99730408e-01]\n",
      " [9.99976873e-01]\n",
      " [9.99947906e-01]\n",
      " [9.99993563e-01]\n",
      " [9.97969925e-01]\n",
      " [2.47249716e-07]\n",
      " [4.41576867e-06]\n",
      " [9.99979615e-01]\n",
      " [9.90187049e-01]\n",
      " [9.99993563e-01]\n",
      " [9.99992371e-01]\n",
      " [1.89575236e-02]\n",
      " [9.45390403e-01]\n",
      " [9.99994874e-01]\n",
      " [9.99996901e-01]\n",
      " [3.47616741e-10]\n",
      " [7.11273821e-03]\n",
      " [9.99311447e-01]\n",
      " [1.65087904e-03]\n",
      " [1.11161463e-03]\n",
      " [9.96394932e-01]\n",
      " [9.99845386e-01]\n",
      " [6.34397496e-04]\n",
      " [2.78612226e-01]\n",
      " [9.98772204e-01]\n",
      " [9.99436796e-01]\n",
      " [9.98526037e-01]\n",
      " [9.90583301e-01]\n",
      " [9.99951005e-01]\n",
      " [9.99862313e-01]\n",
      " [9.99903560e-01]\n",
      " [2.52774098e-05]\n",
      " [3.78536060e-03]\n",
      " [9.98747349e-01]\n",
      " [1.22329935e-01]\n",
      " [9.99605477e-01]\n",
      " [9.99123156e-01]\n",
      " [9.97906566e-01]\n",
      " [9.98984277e-01]\n",
      " [7.94280767e-01]\n",
      " [9.97471452e-01]\n",
      " [9.82854128e-01]\n",
      " [9.45982218e-01]\n",
      " [9.99552071e-01]\n",
      " [9.78890479e-01]\n",
      " [9.99959826e-01]\n",
      " [3.14891963e-07]\n",
      " [9.99838233e-01]\n",
      " [9.99797881e-01]\n",
      " [9.98796105e-01]\n",
      " [9.99395370e-01]\n",
      " [9.99767721e-01]\n",
      " [9.99578893e-01]\n",
      " [9.93345499e-01]\n",
      " [9.99839664e-01]\n",
      " [9.99496818e-01]\n",
      " [9.19903576e-01]\n",
      " [9.96943057e-01]\n",
      " [9.99640107e-01]\n",
      " [9.92707789e-01]\n",
      " [3.75632405e-01]\n",
      " [9.97770429e-01]\n",
      " [9.86027241e-01]\n",
      " [9.99836564e-01]\n",
      " [9.92097259e-01]\n",
      " [9.86432850e-01]\n",
      " [9.97286201e-01]\n",
      " [9.97625053e-01]\n",
      " [9.99567688e-01]\n",
      " [1.77704170e-01]\n",
      " [3.72731425e-02]\n",
      " [5.07523492e-02]\n",
      " [1.16177361e-08]\n",
      " [9.99645114e-01]\n",
      " [9.99976158e-01]\n",
      " [9.99989152e-01]\n",
      " [9.99989152e-01]\n",
      " [2.52434489e-07]\n",
      " [9.79483724e-01]\n",
      " [6.32644689e-04]\n",
      " [6.02245622e-04]\n",
      " [2.52434489e-07]\n",
      " [9.99955535e-01]\n",
      " [9.99989271e-01]\n",
      " [9.99948502e-01]\n",
      " [9.99976516e-01]\n",
      " [9.99986649e-01]\n",
      " [9.99989986e-01]\n",
      " [9.99985218e-01]\n",
      " [9.99497652e-01]\n",
      " [9.99863029e-01]\n",
      " [9.99808729e-01]\n",
      " [1.22308056e-05]\n",
      " [3.06364382e-03]\n",
      " [9.98089135e-01]\n",
      " [9.98103619e-01]\n",
      " [8.05002492e-05]\n",
      " [9.99950409e-01]\n",
      " [9.99938369e-01]\n",
      " [9.99782145e-01]\n",
      " [9.99811113e-01]\n",
      " [9.99735892e-01]\n",
      " [9.99163508e-01]\n",
      " [9.99843836e-01]\n",
      " [9.87451732e-01]\n",
      " [9.99707282e-01]\n",
      " [9.98939812e-01]\n",
      " [9.98026073e-01]\n",
      " [9.93412316e-01]\n",
      " [9.81429636e-01]\n",
      " [9.99893546e-01]\n",
      " [9.99635220e-01]\n",
      " [3.20285745e-02]\n",
      " [9.31338012e-01]\n",
      " [1.20470452e-03]\n",
      " [9.11798060e-01]\n",
      " [9.77166295e-01]\n",
      " [9.99985337e-01]\n",
      " [9.52682555e-01]\n",
      " [9.99986410e-01]\n",
      " [9.91736472e-01]\n",
      " [9.47407424e-01]\n",
      " [9.95384276e-01]\n",
      " [9.99969125e-01]\n",
      " [9.99991655e-01]\n",
      " [9.99601543e-01]\n",
      " [9.98811007e-01]\n",
      " [9.99974132e-01]\n",
      " [9.99434769e-01]\n",
      " [9.99761879e-01]\n",
      " [9.99676824e-01]\n",
      " [9.99253213e-01]\n",
      " [9.99893546e-01]\n",
      " [9.99433100e-01]\n",
      " [9.99433100e-01]\n",
      " [9.99433100e-01]\n",
      " [9.99497652e-01]\n",
      " [9.50972021e-01]\n",
      " [7.48385191e-01]\n",
      " [3.74858268e-02]\n",
      " [9.97423291e-01]\n",
      " [9.97676551e-01]\n",
      " [9.99896049e-01]\n",
      " [9.80617940e-01]\n",
      " [1.26156665e-05]\n",
      " [1.81789471e-06]\n",
      " [9.65636313e-01]\n",
      " [2.55299290e-03]\n",
      " [2.55299290e-03]\n",
      " [2.55299290e-03]\n",
      " [2.55299290e-03]\n",
      " [1.55037483e-09]\n",
      " [1.15712639e-02]\n",
      " [9.99540925e-01]\n",
      " [6.23779139e-03]\n",
      " [9.98800516e-01]\n",
      " [1.29066670e-04]\n",
      " [9.94334102e-01]\n",
      " [7.08949506e-01]\n",
      " [9.23213601e-01]\n",
      " [9.68328536e-01]\n",
      " [9.54360008e-01]\n",
      " [5.97159684e-01]\n",
      " [9.97658610e-01]\n",
      " [9.93156731e-01]\n",
      " [9.95570719e-01]\n",
      " [9.97324944e-01]\n",
      " [6.63559888e-07]\n",
      " [6.31172180e-01]\n",
      " [9.97131824e-01]\n",
      " [3.12881947e-01]\n",
      " [9.36094940e-01]\n",
      " [9.69992876e-01]\n",
      " [5.41752636e-01]\n",
      " [5.41589558e-01]\n",
      " [4.37026680e-01]\n",
      " [8.86410594e-01]\n",
      " [9.42107797e-01]\n",
      " [3.72369051e-01]\n",
      " [8.91552150e-01]\n",
      " [2.70630181e-01]\n",
      " [9.99606550e-01]\n",
      " [9.24621761e-01]\n",
      " [6.17060065e-02]\n",
      " [9.97303009e-01]\n",
      " [9.99667883e-01]\n",
      " [9.97299135e-01]\n",
      " [9.97616529e-01]\n",
      " [9.93048549e-01]\n",
      " [9.93355274e-01]\n",
      " [9.66583848e-01]\n",
      " [9.82237637e-01]\n",
      " [9.98968124e-01]\n",
      " [9.98352170e-01]\n",
      " [9.99894619e-01]\n",
      " [9.68080938e-01]\n",
      " [9.87680316e-01]\n",
      " [9.92379904e-01]\n",
      " [9.99668717e-01]\n",
      " [1.07772846e-03]\n",
      " [9.97313201e-01]\n",
      " [9.97937202e-01]\n",
      " [9.95393038e-01]\n",
      " [9.99750555e-01]\n",
      " [9.96467352e-01]\n",
      " [9.97494459e-01]\n",
      " [9.99114811e-01]\n",
      " [9.53908682e-01]\n",
      " [9.98890102e-01]\n",
      " [9.95684028e-01]\n",
      " [9.71053421e-01]\n",
      " [9.94423330e-01]\n",
      " [9.82781708e-01]\n",
      " [9.98397648e-01]\n",
      " [9.96149778e-01]\n",
      " [9.97160196e-01]\n",
      " [9.98327076e-01]\n",
      " [9.59345818e-01]\n",
      " [9.99678493e-01]\n",
      " [9.64139879e-01]\n",
      " [9.76719499e-01]\n",
      " [9.84777451e-01]\n",
      " [9.90742862e-01]\n",
      " [9.99621391e-01]\n",
      " [3.92870056e-08]\n",
      " [8.99594665e-01]\n",
      " [9.63845313e-01]\n",
      " [7.91641891e-01]\n",
      " [9.96455848e-01]\n",
      " [7.26264552e-04]\n",
      " [3.19412500e-02]\n",
      " [5.34640412e-06]\n",
      " [9.99455273e-01]\n",
      " [2.09260645e-04]\n",
      " [9.99866009e-01]\n",
      " [9.00570691e-01]\n",
      " [9.85927343e-01]\n",
      " [9.78987038e-01]\n",
      " [9.93757606e-01]\n",
      " [8.43159676e-01]\n",
      " [9.97080982e-01]\n",
      " [4.78481616e-06]\n",
      " [1.25239792e-04]\n",
      " [1.41270791e-08]\n",
      " [9.75747883e-01]\n",
      " [2.34340172e-04]\n",
      " [4.39187527e-01]\n",
      " [9.68523860e-01]\n",
      " [9.24342811e-01]\n",
      " [1.32363647e-01]\n",
      " [1.41116634e-01]\n",
      " [1.70888022e-01]\n",
      " [1.12468995e-01]\n",
      " [2.40815178e-01]\n",
      " [1.31080419e-01]\n",
      " [1.18902370e-01]\n",
      " [3.02113593e-02]]\n"
     ]
    }
   ],
   "source": [
    "# plt.plot(x_collect, train_loss_collect, \"r--\")\n",
    "# plt.plot(x_collect, valid_loss_collect, \"g^\")\n",
    "# plt.show()\n",
    "\n",
    "# plt.plot(x_collect, train_acc_collect, \"r--\")\n",
    "# plt.plot(x_collect, valid_acc_collect, \"g^\")\n",
    "# plt.show()\n",
    "\n",
    "test_data = pd.read_csv(\"main_data.csv\")\n",
    "model=build_neural_network()\n",
    "restorer=tf.train.Saver()\n",
    "with tf.Session() as sess:\n",
    "    restorer.restore(sess,\"./hk2.ckpt\")\n",
    "    feed={\n",
    "        model.inputs:test_data,\n",
    "        model.is_training:False\n",
    "    }\n",
    "    test_predict=sess.run(model.predicted,feed_dict=feed)\n",
    "    \n",
    "print(test_predict)\n",
    "\n",
    "np.savetxt(\"predictions.csv\", test_predict, delimiter=\",\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_vulnerability_factor(death_predict):\n",
    "    v_factor = []\n",
    "    v_range = [0.0, 0.09]\n",
    "    for dp in death_predict:\n",
    "        vr = dp[0] * 0.09\n",
    "        if vr < 0.0001:\n",
    "            vr = 0.02 + vr\n",
    "        v_factor.append(vr)\n",
    "    return v_factor\n",
    "\n",
    "# Test\n",
    "dpp = test_predict.tolist()\n",
    "# print(dpp)\n",
    "v_factor = get_vulnerability_factor(dpp)\n",
    "np.savetxt(\"v_factor.csv\", v_factor, delimiter=\",\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[1.5401124983327463e-05],\n",
       " [0.9917449355125427],\n",
       " [0.9999984502792358],\n",
       " [0.9999781847000122],\n",
       " [0.0036730237770825624],\n",
       " [0.9999521970748901],\n",
       " [2.457575101288967e-05],\n",
       " [0.9999560117721558],\n",
       " [0.9999665021896362],\n",
       " [0.9999291896820068],\n",
       " [0.9999953508377075],\n",
       " [0.0003551371628418565],\n",
       " [0.004962591454386711],\n",
       " [0.9997304081916809],\n",
       " [0.9999768733978271],\n",
       " [0.9999479055404663],\n",
       " [0.2786122262477875],\n",
       " [0.9987722039222717],\n",
       " [0.9994367957115173],\n",
       " [0.9985260367393494],\n",
       " [0.9905833005905151],\n",
       " [0.9999510049819946],\n",
       " [0.9998623132705688],\n",
       " [0.9999035596847534],\n",
       " [2.527740980440285e-05],\n",
       " [0.0037853606045246124],\n",
       " [0.9998438358306885],\n",
       " [0.9874517321586609],\n",
       " [0.9997072815895081],\n",
       " [0.9989398121833801],\n",
       " [0.9980260729789734],\n",
       " [0.9934123158454895],\n",
       " [0.9526825547218323],\n",
       " [0.9999864101409912],\n",
       " [0.9998960494995117],\n",
       " [0.9806179404258728],\n",
       " [1.2615666491910815e-05],\n",
       " [1.817894712985435e-06],\n",
       " [0.9656363129615784],\n",
       " [0.002552992897108197],\n",
       " [0.002552992897108197],\n",
       " [0.002552992897108197],\n",
       " [0.9699928760528564],\n",
       " [0.5417526364326477],\n",
       " [0.5415895581245422],\n",
       " [0.4370266795158386],\n",
       " [0.8864105939865112],\n",
       " [0.9421077966690063],\n",
       " [0.37236905097961426],\n",
       " [3.928700564870269e-08],\n",
       " [0.8995946645736694],\n",
       " [0.9638453125953674],\n",
       " [0.791641891002655],\n",
       " [0.9964558482170105],\n",
       " [0.0007262645522132516],\n",
       " [4.784816155734006e-06],\n",
       " [0.00012523979239631444],\n",
       " [1.4127079062120629e-08],\n",
       " [0.9757478833198547],\n",
       " [0.00023434017202816904],\n",
       " [0.43918752670288086],\n",
       " [0.9685238599777222],\n",
       " [0.9243428111076355],\n",
       " [0.1708880215883255],\n",
       " [0.11246899515390396],\n",
       " [0.2408151775598526],\n",
       " [0.13108041882514954],\n",
       " [0.11890237033367157],\n",
       " [0.03021135926246643]]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_predict.tolist()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
